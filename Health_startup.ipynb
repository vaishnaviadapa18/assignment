{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9757698f",
   "metadata": {},
   "source": [
    "Importing all the libraries that are needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49be0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61852279",
   "metadata": {},
   "source": [
    "Creating a summy dataset. We are craeting dummy sequence of integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dcb60263",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(Dataset):\n",
    "    def __init__(self, num_samples, seq_length, vocab_size):\n",
    "        self.data = torch.randint(0, vocab_size, (num_samples, seq_length))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a281085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10000\n",
    "seq_length = 20\n",
    "vocab_size = 100 \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "151c0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DummyDataset(sample_size, seq_length, vocab_size)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "644973e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 38, 75, 46, 38, 50, 93,  9, 53, 54, 90, 14, 15, 92, 20,  8, 63, 30,\n",
      "        97, 89])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24db3416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 20])\n",
      "tensor([97, 28, 63, 71, 73, 81, 38, 99, 28, 14, 16, 49, 35, 83, 60, 17, 58, 48,\n",
      "        34, 28])\n"
     ]
    }
   ],
   "source": [
    "for i in dataloader:\n",
    "    print(i.shape)\n",
    "    print(i[0])\n",
    "    break #just once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88605279",
   "metadata": {},
   "source": [
    "We need to create an embedding layer. Essentially we are taking positions or positional indeces as inputs. \n",
    "We will get corresponding embeddings which is input + positional sequence as an output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79fa5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0f71d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(100, 64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34230d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(20, 64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embeddings = nn.Embedding(seq_length, embedding_dim)\n",
    "position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e58b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LearnablePositionalEncoding(seq_length, embedding_dim,positions):\n",
    "    position_embeddings = nn.Embedding(seq_length, embedding_dim)\n",
    "    return position_embeddings(positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421a4d7",
   "metadata": {},
   "source": [
    "In the \"for loop\" here, we are creating multiple linear encoder layers and a final output layer.We will pass positions and input sequences as inputs, pass them through layers, embed and get the final predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d5d173e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelWithPositionalEncoding(vocab_size, embedding_dim, seq_length, num_layers,positions):\n",
    "    embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    positional_encoding = LearnablePositionalEncoding(seq_length, embedding_dim,positions)\n",
    "    encoder_layers = nn.ModuleList([nn.Linear(embedding_dim, embedding_dim) for _ in range(num_layers)])\n",
    "    output_layer = nn.Linear(embedding_dim, vocab_size)\n",
    "    embedded = embedding(inputs) + positional_encoding\n",
    "    for layer in encoder_layers:\n",
    "        embedded = layer(embedded)\n",
    "    output = output_layer(embedded)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbd0fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6c4df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ef5d0",
   "metadata": {},
   "source": [
    "Here we are creating batches of data in the second loop, in each iteration, we do compute predictions using the previous function and the end of each iteration, we get the loss at the end of each iteration printed on here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d951e5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 1/10, Loss: 98.55494169229135\n",
      "i 2/10, Loss: 103.2007722991724\n",
      "i 3/10, Loss: 107.84680554204094\n",
      "i 4/10, Loss: 112.49128167697796\n",
      "i 5/10, Loss: 117.13768479009025\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    loss = 0\n",
    "    for j in dataloader:\n",
    "        inputs = batch[:, :-1] #exclude last one\n",
    "        targets = batch[:, 1:] #prediction\n",
    "        positions = torch.arange(seq_length - 1)  #to length - 2 \n",
    "        optimizer.zero_grad()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        outputs = ModelWithPositionalEncoding(vocab_size, embedding_dim, seq_length, num_layers,positions)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), targets.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"i {i+1}/{10}, Loss: {total_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2783b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
